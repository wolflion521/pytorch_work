{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoEncoder\n",
    "### structure\n",
    "    3 layer conv and downsample          \n",
    "    3 layer transpose conv upsample\n",
    "    loss: Mean Square Error\n",
    "    optimizer: Adam\n",
    "### functions\n",
    "    import torch.nn as nn\n",
    "    3 layer conv and downsample\n",
    "        conv:  nn.Conv2d(inputlayerchannels,outputlayerchannels,kernelsize,padding)\n",
    "        downsample:nn.MaxPool2d(2,2)\n",
    "    3 layer transpose conv upsample: nn.ConvTranspose2d(inputlayerchannels,outputlayerchannels,kernelsize,stride=2)\n",
    "    activation function:import torch.nn.functional as F   F.relu   F.sigmoid\n",
    "    loss: Mean Square Error   nn.MSELoss(predicts,targets)\n",
    "    optimizer: Adam        torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    Dataloader:torch.utils.data.DataLoader\n",
    "    reshape:  certainTensor.view(batch_size,channel,height,width)\n",
    "    get the output value of a layer: outputofalayer.detach().numpy() can get the auto_grad values away only keep the value of layeroutput\n",
    "### how to organize code\n",
    "    Write a class(nn.Module) to contain the whole network sturcture:__init__ and forward need to rewrite. \n",
    "    Conv and Transpose_Conv should keep the weights, while pool and relu don't need to keep paras. And nn calls layers, Function calls funcs,layers have paras so they should be the variable of network class.\n",
    "    instanciate the network class.\n",
    "    Define Loss \n",
    "    Define opitimizer\n",
    "    Image transform to Tensor, and load use Dataloader\n",
    "    iterate dataloader get the input and target batch to TRAIN the model\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs,targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss.item()*images.size(0) get total batch loss\n",
    "        train_loss update(each epoch or each batch)\n",
    "    TEST the model: get some data from test set, eg. one batch data. output = model(test_data)get the output. And RESHAPE \n",
    "    some visualize: fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "    for noisy_imgs, row in zip([noisy_imgs, output], axes):\n",
    "        for img, ax in zip(noisy_imgs, row):\n",
    "            ax.imshow(np.squeeze(img), cmap='gray')\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9911e0f68427>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_data = datasets.MNIST(root='data',train=True,download=Ture,transform=transform)\n",
    "test_data = datasets.MNIST(root='data',train=False,download=Ture,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
